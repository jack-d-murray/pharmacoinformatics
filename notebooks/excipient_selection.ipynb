{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924f7565-aeac-46a7-8cb5-6f7cc286c0a1",
   "metadata": {},
   "source": [
    "# 3. Excipient Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe44ed-1ccc-488c-bf87-d8a21454dc0e",
   "metadata": {},
   "source": [
    "This notebook describes the use of association rule learning and exploratory hypothesis testing to inform excipient selection. Association rule learning applies a frequent itemset approach to identify interesting or meaningful excipient patterns in oral tablet formulation data, independent of the active ingredient. Exploratory hypothesis testing aims to detect differences in the distribution of chemical descriptors between the set of drugs formulated with each excipient and the set of drugs not formulated with the excipient of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52a17d-ceb8-474d-91a5-0e3704bd9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arulespy is a Python interface for the arules R package and is built with rpy2. As rpy2 does not fully support Windows, Windows users may\n",
    "# experience an error where the kernal dies when importing below libraries/packages. Information on possible workarounds are available via\n",
    "# the GitHub page https://github.com/mhahsler/arulespy and the Python Package Index page https://pypi.org/project/arulespy/\n",
    "# import os\n",
    "# os.environ[\"R_HOME\"] = #R_Path\n",
    "# os.environ[\"PATH\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Display\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython import get_ipython as get_ipython\n",
    "from IPython.display import IFrame\n",
    "import rpy2.robjects.packages as packages\n",
    "\n",
    "# Frequent itemset mining\n",
    "from arulespy.arules import Transactions, apriori, parameters\n",
    "from arulespy.arulesViz import plot, inspectDT, ruleExplorer\n",
    "from rpy2.ipython.ggplot import image_png\n",
    "from rpy2 import robjects as ro\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Exploratory hypothesis testing\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import false_discovery_control\n",
    "\n",
    "# Cheminformatics\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Lipinski\n",
    "\n",
    "# Others\n",
    "import ast\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7263254-0a56-4c41-a735-bfda9409ea23",
   "metadata": {},
   "source": [
    "## Association Rule Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5ec74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate dataframe suitable for analysis\n",
    "\n",
    "original_df = pd.read_csv(\"../csv_files/final_master_df.csv\", index_col = 0)\n",
    "oral = original_df[original_df[\"Route\"] == \"Oral\"][[\"Dosage Form\", \"Excipients_Final\"]]\n",
    "oral_tablets = oral[oral[\"Dosage Form\"] == \"Tablet\"][\"Excipients_Final\"].apply(ast.literal_eval)\n",
    "oral_tablets.drop_duplicates(inplace=True)\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(oral_tablets).transform(oral_tablets)\n",
    "oral_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "oral_df.drop_duplicates(inplace=True)\n",
    "trans = Transactions.from_df(oral_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c8d39-aad1-4f21-9be2-7db989befe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_rules = apriori(trans,\n",
    "               parameter = parameters({\"supp\": 0.01, \"conf\": 0.01}),\n",
    "               control = parameters({\"verbose\": False}),\n",
    "               minlen=2,\n",
    "               maxlen=2)\n",
    "streamlit_rules_df = streamlit_rules.as_df().round(2)\n",
    "streamlit_rules_df.to_csv(\"../csv_files/streamlit_app_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e234e34-2261-41ef-9baf-81e0ac60bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_graph = apriori(trans,\n",
    "               parameter = parameters({\"supp\": 0.01, \"conf\": 0.6}),\n",
    "               control = parameters({\"verbose\": False}),\n",
    "                minlen=2,\n",
    "                maxlen=2)\n",
    "rules_df = rules_graph.as_df()\n",
    "rules_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6901d7-ca61-479f-8422-f2543d505efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing all instances that contain both Copovidone and Sorbitan Monolaurate\n",
    "oral1 = original_df[original_df[\"Route\"] == \"Oral\"][[\"Dosage Form\", \"Excipients_Final\", \"Active substance\", \"Marketing authorisation holder/company name\"]]\n",
    "oral_tablets1 = oral1[oral1[\"Dosage Form\"] == \"Tablet\"][\"Excipients_Final\"].apply(ast.literal_eval)\n",
    "oral_tablets1.drop_duplicates(inplace=True)\n",
    "def get_indices(lst):\n",
    "    return \"COPOVIDONE\" in lst and \"SORBITAN MONOLAURATE\" in lst\n",
    "mask = oral_tablets1.apply(get_indices)\n",
    "\n",
    "# Get the indices where the mask is True\n",
    "indices = mask[mask].index.tolist()\n",
    "oral1.loc[indices][[\"Active substance\", \"Marketing authorisation holder/company name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e77ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing all instances that contain both Hypromellose Acetate Succinate and Croscarmellose Sodium\n",
    "oral1 = original_df[original_df[\"Route\"] == \"Oral\"][[\"Dosage Form\", \"Excipients_Final\", \"Active substance\", \"Marketing authorisation holder/company name\"]]\n",
    "oral_tablets1 = oral1[oral1[\"Dosage Form\"] == \"Tablet\"][\"Excipients_Final\"].apply(ast.literal_eval)\n",
    "oral_tablets1.drop_duplicates(inplace=True)\n",
    "def get_indices(lst):\n",
    "    return \"HYPROMELLOSE ACETATE SUCCINATE\" in lst and \"CROSCARMELLOSE SODIUM\" in lst\n",
    "mask = oral_tablets1.apply(get_indices)\n",
    "\n",
    "# Get the indices where the mask is True\n",
    "indices = mask[mask].index.tolist()\n",
    "oral1.loc[indices][[\"Active substance\", \"Marketing authorisation holder/company name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "lhs = rules_df[(rules_df[\"LHS\"] == \"{COPOVIDONE}\")|(rules_df[\"LHS\"] == \"{HYPROMELLOSE ACETATE SUCCINATE}\")]\n",
    "rhs = rules_df[(rules_df[\"RHS\"] == \"{COPOVIDONE}\" )|(rules_df[\"RHS\"] == \"{HYPROMELLOSE ACETATE SUCCINATE}\")]\n",
    "lhs_and_rhs = pd.concat([lhs, rhs])\n",
    "lhs_and_rhs = lhs_and_rhs[lhs_and_rhs[\"lift\"] > 1]\n",
    "list_for_network = list(set(lhs_and_rhs[\"LHS\"]).union(set(lhs_and_rhs[\"RHS\"])))\n",
    "mask = rules_df[\"LHS\"].isin(list_for_network) & rules_df[\"RHS\"].isin(list_for_network)\n",
    "full_network = rules_df[mask]\n",
    "full_network = full_network[full_network[\"lift\"] > 1]\n",
    "def clean_text(text):\n",
    "    cleaned_text = text.strip(\"{}\").strip().replace(\" \", \"\\n\")\n",
    "    return cleaned_text.capitalize()\n",
    "full_network[\"RHS\"] = full_network[\"RHS\"].apply(clean_text)\n",
    "full_network[\"LHS\"] = full_network[\"LHS\"].apply(clean_text)\n",
    "full_network.to_csv(\"../results/association_rules_hpmcas_pvpva64.csv\")\n",
    "full_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = [\n",
    "    \"Hypromellose\\nacetate\\nsuccinate\",\n",
    "    \"Copovidone\",\n",
    "    \"Sorbitan\\nmonolaurate\",\n",
    "    \"Polyethylene\\nglycol\",\n",
    "    \"Iron\\noxide\",\n",
    "    \"Silicon\\ndioxide,\\nanhydrous\",\n",
    "    \"Talc\",\n",
    "    \"Titanium\\ndioxide\",\n",
    "    \"Croscarmellose\\nsodium\",\n",
    "    \"Magnesium\\nstearate\",\n",
    "    \"Microcrystalline\\ncellulose\"\n",
    "]\n",
    "\n",
    "excip_of_interest = [\n",
    "    \"Hypromellose\\nacetate\\nsuccinate\",\n",
    "    \"Copovidone\"\n",
    "]\n",
    "\n",
    "other_excip = [x for x in positions if x not in excip_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3417f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Figure 7A\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "# Adding edges and rows\n",
    "for index, row in full_network.iterrows():\n",
    "    G.add_edge(row[\"LHS\"], row[\"RHS\"], confidence=row[\"confidence\"])\n",
    "\n",
    "# Setting up positioning\n",
    "num_nodes_semicircle = 9\n",
    "radius = 1\n",
    "angle_between_nodes = np.pi / (num_nodes_semicircle - 1)\n",
    "pos = dict()\n",
    "for i in range(3, 12):\n",
    "    angle = (i - 3) * angle_between_nodes \n",
    "    x = radius * np.cos(angle)\n",
    "    y = radius * np.sin(angle) + 0.38\n",
    "    pos[positions[i-1]] = (x, y)   \n",
    "pos[positions[0]] = (pos[positions[7]][0] + 0.1, 0.1) # HPMCAS\n",
    "pos[positions[1]] = (pos[positions[5]][0] - 0.1, 0.1) # PVPVA\n",
    "\n",
    "confidences = [d[\"confidence\"] for u, v, d in G.edges(data=True)]\n",
    "norm = mcolors.Normalize(vmin=0.6, vmax=1)\n",
    "cmap = cm.Reds\n",
    "colors = [cmap(norm(d[\"confidence\"])) for u, v, d in G.edges(data=True)]\n",
    "\n",
    "# Plotting\n",
    "nx.draw(G,\n",
    "        pos, \n",
    "        node_size=2500, \n",
    "        node_color=\"w\", \n",
    "        edgecolors= \"k\",\n",
    "        edge_color = colors,\n",
    "        width=0.7,\n",
    "        with_labels=False, \n",
    "        arrows=True,\n",
    "        connectionstyle=\"arc3,rad=0.1\",\n",
    "        labels={node: node for node in G.nodes()}\n",
    "       )\n",
    "nx.draw_networkx_labels(G.subgraph(other_excip),\n",
    "                        {k: v for k, v in pos.items() if k in other_excip},\n",
    "                        font_size=5.8)\n",
    "\n",
    "nx.draw_networkx_labels(G.subgraph(excip_of_interest),\n",
    "                        {k: v for k, v in pos.items() if k in excip_of_interest},\n",
    "                        font_weight=\"bold\",\n",
    "                        font_size=5.8)\n",
    "\n",
    "\n",
    "plt.text(-1.1, 1.4, \"A\", fontsize=20, fontweight=\"bold\")\n",
    "# Colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar_ax = plt.gcf().add_axes([1.03, 0.35, 0.015, 0.35])  \n",
    "cbar = plt.colorbar(sm, cax=cbar_ax, orientation=\"vertical\")  \n",
    "cbar.ax.tick_params(labelsize=8)\n",
    "cbar.set_label(\"Confidence\", fontsize=7)\n",
    "\n",
    "\n",
    "# Saving figure\n",
    "plt.savefig(\"../figures/network_plot_confidence.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04903db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Figure 7B\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "# Adding edges and rows\n",
    "for index, row in full_network.iterrows():\n",
    "    G.add_edge(row[\"LHS\"], row[\"RHS\"], lift=row[\"lift\"])\n",
    "\n",
    "# Setting up positioning\n",
    "num_nodes_semicircle = 9\n",
    "radius = 1\n",
    "angle_between_nodes = np.pi / (num_nodes_semicircle - 1)\n",
    "pos = dict()\n",
    "for i in range(3, 12):\n",
    "    angle = (i - 3) * angle_between_nodes \n",
    "    x = radius * np.cos(angle)\n",
    "    y = radius * np.sin(angle) + 0.38\n",
    "    pos[positions[i-1]] = (x, y)   \n",
    "pos[positions[0]] = (pos[positions[7]][0] + 0.1, 0.1) # HPMCAS\n",
    "pos[positions[1]] = (pos[positions[5]][0] - 0.1, 0.1) # PVPVA\n",
    "\n",
    "# Normalizing the confidence values for the colormap\n",
    "lifts = [d[\"lift\"] for u, v, d in G.edges(data=True)]\n",
    "norm = mcolors.Normalize(vmin=1, vmax=2)\n",
    "cmap = cm.Blues  # You can choose any colormap you prefer\n",
    "colors = [cmap(norm(d[\"lift\"])) for u, v, d in G.edges(data=True)]\n",
    "\n",
    "# Plotting\n",
    "nx.draw(G,\n",
    "        pos, \n",
    "        node_size=2500, \n",
    "        node_color=\"w\", \n",
    "        edgecolors= \"k\",\n",
    "        edge_color = colors,\n",
    "        width=0.7,\n",
    "        with_labels=False, \n",
    "        arrows=True,\n",
    "        connectionstyle=\"arc3,rad=0.1\",\n",
    "        labels={node: node for node in G.nodes()}\n",
    "       )\n",
    "nx.draw_networkx_labels(G.subgraph(other_excip),\n",
    "                        {k: v for k, v in pos.items() if k in other_excip},\n",
    "                        font_size=5.8)\n",
    "\n",
    "nx.draw_networkx_labels(G.subgraph(excip_of_interest),\n",
    "                        {k: v for k, v in pos.items() if k in excip_of_interest},\n",
    "                        font_weight=\"bold\",\n",
    "                        font_size=5.8)\n",
    "plt.text(-1.1, 1.4, \"B\", fontsize=20, fontweight=\"bold\")\n",
    "# Colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar_ax = plt.gcf().add_axes([1.03, 0.35, 0.015, 0.35])  \n",
    "cbar = plt.colorbar(sm, cax=cbar_ax, orientation=\"vertical\", extend=\"max\")  \n",
    "cbar.ax.tick_params(labelsize=8)\n",
    "cbar.set_label(\"Lift\", fontsize=7)\n",
    "\n",
    "# # Saving figure\n",
    "plt.savefig(\"../figures/network_plot_lift.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cccd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = Transactions.from_df(oral_df)\n",
    "rules = apriori(trans,\n",
    "               parameter = parameters({\"supp\": 0.01, \"conf\": 0.6}),\n",
    "               control = parameters({\"verbose\": False}),\n",
    "               minlen=2)\n",
    "rules_df = rules.as_df().round(2)\n",
    "to_plot = rules_df[(rules_df[\"lift\"]>1)]\n",
    "to_plot.sort_values(by=\"lift\", inplace=True)\n",
    "rules_df.to_csv(\"../results/all_association_rules.csv\")\n",
    "to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc93df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jitter_support = to_plot[\"support\"] + np.random.normal(loc=0, scale=0.002, size=len(to_plot))\n",
    "jitter_confidence = to_plot[\"confidence\"] + np.random.normal(loc=0, scale=0.002, size=len(to_plot))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "scatter = ax.scatter(x=jitter_support, y=jitter_confidence, c=to_plot[\"lift\"], cmap=\"Reds\", s=10, norm= mcolors.Normalize(vmin=1, vmax=5))\n",
    "\n",
    "plt.colorbar(scatter, label=\"Lift\", extend=\"max\")\n",
    "\n",
    "ax.set_xlabel(\"Support\")\n",
    "ax.set_ylabel(\"Confidence\")\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.grid(True)\n",
    "ax.set_xlim(left=0.0)\n",
    "\n",
    "plt.savefig(\"../figures/rules_plot.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0108b7-a55a-4524-999d-2c419ffb829e",
   "metadata": {},
   "source": [
    "## Exploratory Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ffd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_substance_df = pd.read_csv(\"../csv_files/adding_chembl_to_actives.csv\", index_col=0)\n",
    "active_substance_df = active_substance_df[~active_substance_df[\"IsomericSMILES\"].str.contains(\"\\.\")][[\"active_PSS\", \"IsomericSMILES\"]] # get rid of multicomponents\n",
    "active_substance_df.drop_duplicates(subset=\"active_PSS\", inplace=True)\n",
    "active_set = set(active_substance_df[\"active_PSS\"])\n",
    "active_substance_df[\"Mol\"] = active_substance_df[\"IsomericSMILES\"].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "active_substance_df[\"MolWt\"] = active_substance_df[\"Mol\"].apply(lambda x: Descriptors.MolWt(x))\n",
    "active_substance_df[\"HDonors\"] = active_substance_df[\"Mol\"].apply(lambda x: Lipinski.NumHDonors(x))\n",
    "active_substance_df[\"HAcceptors\"] = active_substance_df[\"Mol\"].apply(lambda x: Lipinski.NumHAcceptors(x))\n",
    "active_substance_df[\"RotB\"] = active_substance_df[\"Mol\"].apply(lambda x: Lipinski.NumRotatableBonds(x))\n",
    "active_substance_df[\"TPSA\"] = active_substance_df[\"Mol\"].apply(lambda x: Descriptors.TPSA(x))\n",
    "active_substance_df[\"LogP\"] = active_substance_df[\"Mol\"].apply(lambda x: Descriptors.MolLogP(x))\n",
    "active_substance_df.rename(columns={\"active_PSS\": \"drug\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9485d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploratory_testing = original_df[(original_df[\"Route\"] == \"Oral\") & (original_df[\"Dosage Form\"] == \"Tablet\")][[\"actives_in_dosage_form\", \"Excipients_Final\"]]\n",
    "exploratory_testing[\"actives_in_dosage_form\"] = exploratory_testing[\"actives_in_dosage_form\"].apply(lambda x: x.upper().strip().split(\",\"))\n",
    "exploratory_testing = exploratory_testing.explode(\"actives_in_dosage_form\")\n",
    "exploratory_testing[\"actives_in_dosage_form\"] = exploratory_testing[\"actives_in_dosage_form\"].apply(lambda x: x.strip())\n",
    "exploratory_testing[\"Excipients_Final\"] = exploratory_testing[\"Excipients_Final\"].apply(ast.literal_eval)\n",
    "exploratory_testing = (exploratory_testing[exploratory_testing[\"actives_in_dosage_form\"].isin(active_set)]\n",
    "             .groupby(\"actives_in_dosage_form\")[\"Excipients_Final\"]\n",
    "             .sum()\n",
    "             .apply(lambda x: list(set(x)))\n",
    "             .reset_index())\n",
    "# Getting excipients with a count greater >= 10\n",
    "list_of_excipients = list(exploratory_testing[\"Excipients_Final\"].explode())\n",
    "excipient_counts = Counter(list_of_excipients)\n",
    "selected_excipients = [item for item, count in excipient_counts.items() if count >= 10]\n",
    "for excipient in selected_excipients:\n",
    "    exploratory_testing[excipient] = exploratory_testing[\"Excipients_Final\"].apply(lambda x: excipient in x)\n",
    "exploratory_testing.rename(columns={\"actives_in_dosage_form\": \"drug\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b090e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_testing = pd.merge(exploratory_testing, active_substance_df, how=\"left\", on=\"drug\")\n",
    "output_columns = df_for_testing[selected_excipients]\n",
    "predictors = [\"MolWt\", \"HDonors\", \"HAcceptors\", \"RotB\", \"TPSA\", \"LogP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b852b58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def perform_mannwhitneyu_test(df, input_col, output_col):\n",
    "    included = df[df[output_col] == 1][input_col]\n",
    "    not_included = df[df[output_col] == 0][input_col]\n",
    "    statistic, p_value = mannwhitneyu(included, not_included, alternative=\"two-sided\")\n",
    "    return (output_col, input_col, statistic, p_value)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Collect all p-values and other test results\n",
    "for input_col in predictors:\n",
    "    for output_col in output_columns:\n",
    "        result = perform_mannwhitneyu_test(df_for_testing, input_col, output_col)\n",
    "        results.append(result)\n",
    "\n",
    "# Extract p-values for BH correction\n",
    "p_values = [result[3] for result in results]\n",
    "\n",
    "# Apply FDR\n",
    "corrected_p_values = false_discovery_control(p_values)\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=[\"Output Column\", \"Input Column\", \"Statistic\", \"P-Value\"])\n",
    "df_results[\"Corrected P\"] = false_discovery_control(p_values)\n",
    "df_results[df_results[\"Corrected P\"] < 0.05]\n",
    "df_results.to_csv(\"../results/exploratory_hypothesis_testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e8829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating lists of values to plot normalised against the Ro5 or Veber's Rules as appropriate\n",
    "\n",
    "# Copovidone TPSA\n",
    "copovidone_tpsa = df_for_testing[df_for_testing[\"COPOVIDONE\"] == True][\"TPSA\"]/140\n",
    "not_copovidone_tpsa = df_for_testing[df_for_testing[\"COPOVIDONE\"] == False][\"TPSA\"]/140\n",
    "\n",
    "# Copovidone HDonors\n",
    "copovidone_hdonors = df_for_testing[df_for_testing[\"COPOVIDONE\"] == True][\"HDonors\"]/5\n",
    "not_copovidone_hdonors = df_for_testing[df_for_testing[\"COPOVIDONE\"] == False][\"HDonors\"]/5\n",
    "\n",
    "# Copovidone HAcceptors\n",
    "copovidone_hacceptors = df_for_testing[df_for_testing[\"COPOVIDONE\"] == True][\"HAcceptors\"]/10\n",
    "not_copovidone_hacceptors = df_for_testing[df_for_testing[\"COPOVIDONE\"] == False][\"HAcceptors\"]/10\n",
    "\n",
    "# Copovidone MolWt\n",
    "copovidone_molwt = df_for_testing[df_for_testing[\"COPOVIDONE\"] == True][\"MolWt\"]/500\n",
    "not_copovidone_molwt = df_for_testing[df_for_testing[\"COPOVIDONE\"] == False][\"MolWt\"]/500\n",
    "\n",
    "# Maize Starch TPSA\n",
    "maize_tpsa = df_for_testing[df_for_testing[\"MAIZE STARCH\"] == True][\"TPSA\"]/140\n",
    "not_maize_tpsa = df_for_testing[df_for_testing[\"MAIZE STARCH\"] == False][\"TPSA\"]/140\n",
    "\n",
    "# Maize Starch HAcceptors\n",
    "maize_hacceptors = df_for_testing[df_for_testing[\"MAIZE STARCH\"] == True][\"HAcceptors\"]/10\n",
    "not_maize_hacceptors = df_for_testing[df_for_testing[\"MAIZE STARCH\"] == False][\"HAcceptors\"]/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cacd97-f1d1-4283-bf8f-74acdcf6f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting data using boxplots\n",
    "\n",
    "data = [\n",
    "    copovidone_molwt, not_copovidone_molwt,  \n",
    "    copovidone_hdonors, not_copovidone_hdonors,   \n",
    "    copovidone_hacceptors, not_copovidone_hacceptors,\n",
    "    copovidone_tpsa, not_copovidone_tpsa,   \n",
    "    maize_hacceptors, not_maize_hacceptors,  \n",
    "    maize_tpsa, not_maize_tpsa         \n",
    "]\n",
    "\n",
    "grouped_data = [data[i:i+2] for i in range(0, len(data), 2)]\n",
    "\n",
    "# f-strings made code too long and complicated, values copied manually\n",
    "x_labels = [r\"$\\bf{MolWt}$\" \"\\np<0.001\\nAdjusted p<0.001\\nU=2056.0\", \n",
    "          r\"$\\bf{HBD}$\" \"\\np=0.001\\nAdjusted p=0.034\\nU=1787.5\", \n",
    "          r\"$\\bf{HBA}$\" \"\\np<0.001\\nAdjusted p=0.002\\nU=1971.0\", \n",
    "          r\"$\\bf{TPSA}$\" \"\\np<0.001\\nAdjusted p<0.001\\nU=2057.0\", \n",
    "          r\"$\\bf{HBA}$\" \"\\np<0.001\\nAdjusted p=0.013\\nU=972.0\", \n",
    "          r\"$\\bf{TPSA}$\" \"\\np<0.001\\nAdjusted p=0.013\\nU=951.5\"]\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Positioning bars side-by-side\n",
    "positions = []\n",
    "for i in range(len(grouped_data)):\n",
    "    positions.extend([i*4+1, i*4+2]) \n",
    "\n",
    "for i, group in enumerate(grouped_data):\n",
    "    for j, var in enumerate(group):\n",
    "        x = np.random.normal(positions[i*2 + j], 0.05, size=len(var))  \n",
    "        plt.scatter(x, var, color=\"gray\", alpha=0.4, s=6)\n",
    "\n",
    "boxplot = plt.boxplot(\n",
    "    [item for sublist in grouped_data for item in sublist], \n",
    "    positions=positions, \n",
    "    patch_artist=True, \n",
    "    medianprops=dict(color=\"black\"),\n",
    "    widths=0.75\n",
    ")\n",
    "\n",
    "# Customising the colouring and layout of the plot\n",
    "edge_colors = [\"C0\", \"black\", \"C0\", \"black\", \"C0\", \"black\", \"C0\", \"black\", \"C1\", \"black\", \"C1\", \"black\"]\n",
    "line_width=1.6\n",
    "for i, (box, whisker1, whisker2, cap1, cap2, median, fliers) in enumerate(zip(boxplot[\"boxes\"], \n",
    "                                                                        boxplot[\"whiskers\"][::2], \n",
    "                                                                        boxplot[\"whiskers\"][1::2], \n",
    "                                                                        boxplot[\"caps\"][::2], \n",
    "                                                                        boxplot[\"caps\"][1::2],\n",
    "                                                                        boxplot[\"medians\"],\n",
    "                                                                        boxplot[\"fliers\"])):\n",
    "    box.set_edgecolor(edge_colors[i])\n",
    "    box.set_linewidth(line_width)\n",
    "    whisker1.set_color(edge_colors[i])\n",
    "    whisker1.set_linewidth(line_width) \n",
    "    whisker2.set_color(edge_colors[i])\n",
    "    whisker2.set_linewidth(line_width)\n",
    "    cap1.set_color(edge_colors[i])\n",
    "    cap1.set_linewidth(line_width) \n",
    "    cap2.set_color(edge_colors[i])\n",
    "    cap2.set_linewidth(line_width) \n",
    "    median.set_color(edge_colors[i])\n",
    "    median.set_linewidth(line_width)\n",
    "    fliers.set_markeredgecolor(edge_colors[i])\n",
    "for patch in boxplot[\"boxes\"]:\n",
    "    patch.set_facecolor(\"none\")\n",
    "\n",
    "\n",
    "plt.xticks([i*4 + 1.5 for i in range(len(grouped_data))], x_labels, fontsize=12)\n",
    "plt.ylabel(\"Normalized Values\", fontsize=16)\n",
    "\n",
    "plt.xlim(-0.5, max(positions) + 1.5)  # Adding additional whitespace on each side\n",
    "plt.gca().yaxis.grid(True)\n",
    "plt.gca().xaxis.grid(False)\n",
    "\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], color=\"C0\", lw=2, label=\"Formulated with copovidone\"),\n",
    "    plt.Line2D([0], [0], color=\"C1\", lw=2, label=\"Formulated with maize starch\"),\n",
    "    plt.Line2D([0], [0], color=\"black\", lw=2, label=\"Not formulated with excipient of interest\")\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc=\"upper right\", fontsize = 14)\n",
    "\n",
    "plt.savefig(\"../figures/hypothesis_testing.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
